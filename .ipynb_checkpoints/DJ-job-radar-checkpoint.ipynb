{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only operate when the newjoblist need to be resetted\n",
    "import csv\n",
    "with open('newjoblist.csv','w',newline='') as g:\n",
    "    writer = csv.writer(g)\n",
    "    header = ['Title','Company','Location','Date','URL']\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.83 s, sys: 79 ms, total: 1.91 s\n",
      "Wall time: 28.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "def scrape_indeed(data):\n",
    "    jobs= []\n",
    "    all_h2 = data.find_all('h2', attrs={'class':\"jobtitle\"}) \n",
    "    #it's a weirdo page that the last item's 'class' is different from above 9, so that we use its sub label h2.\n",
    "    for i in all_h2:\n",
    "        job = []\n",
    "        job.append(i.a['title'])\n",
    "        job.append(i.parent.find('span', attrs={'class':\"company\"}).text.strip()) \n",
    "        #use .parent back to the higher label\n",
    "        job.append(i.parent.find('span', attrs={'class':\"location\"}).text.strip())\n",
    "        job.append(i.parent.find('span', attrs={'class':\"date\"}).text.strip())\n",
    "        job.append('https://www.indeed.com/viewjob?jk={}'.format(i['id'][3:]))\n",
    "        jobs.append(job)\n",
    "    return jobs\n",
    "\n",
    "def scrape_careers(data):\n",
    "    jobs= []\n",
    "    all_div = data.find_all('div', attrs={'class':\"bti-ui-job-detail-container\"}) \n",
    "    for i in all_div:\n",
    "        job=[]\n",
    "        job.append(i.find('a').text)\n",
    "        job.append(i.find('div', attrs={'class':\"bti-ui-job-result-detail-employer\"}).text.strip())\n",
    "        job.append(i.find('div', attrs={'class':\"bti-ui-job-result-detail-location\"}).text.strip())\n",
    "        job.append(i.find('div', attrs={'class':\"bti-ui-job-result-detail-age\"}).text.strip())\n",
    "        job.append('https://careers.journalists.org{}'.format(i.find('a')['href']))\n",
    "        jobs.append(job)\n",
    "    return jobs\n",
    "\n",
    "def scrape_jobsdb(data):\n",
    "    jobs= []\n",
    "    all_div = data.find_all('div', attrs={'class':\"_3ASfTyv _2EUSthc\"}) \n",
    "    for i in all_div:\n",
    "        job=[]\n",
    "        job.append(i.find('div', attrs={'class':\"_3gfm7U9 _3ho-Knb _2swcdgn\"}).a.text)\n",
    "        job.append(i.find('div', attrs={'class':\"_1NdWRqw _3ho-Knb _2swcdgn\"}).find('span').text)\n",
    "        job.append(i.find('div', attrs={'class':\"_124cxoK _3ho-Knb _2swcdgn\"}).find('span').text)\n",
    "        job.append(i.find('span', attrs={'class':\"JG37Vx2 _3Re95QG _2XGgj_O\"}).find('span').text)\n",
    "        job.append(i.find('div', attrs={'class':\"_3gfm7U9 _3ho-Knb _2swcdgn\"}).a['href'])\n",
    "        jobs.append(job)\n",
    "    return jobs\n",
    "\n",
    "def select_one_scraped(page_url):\n",
    "    r = requests.get(page_url).text\n",
    "    data = BeautifulSoup(r,\"html.parser\")\n",
    "    if page_url.find('indeed')!=-1:\n",
    "        return scrape_indeed(data)\n",
    "    elif page_url.find('careers')!=-1:\n",
    "        return scrape_careers(data)\n",
    "    elif page_url.find('jobsdb')!=-1:\n",
    "        return scrape_jobsdb(data)\n",
    "\n",
    "def scrape_all_pages(base_url,step):\n",
    "    all_jobs=[]\n",
    "    level = 0\n",
    "    while True: \n",
    "        level += step  #level is in url to indiccate different pages' index\n",
    "        page_url = '{}{}'.format(base_url,level)\n",
    "        jobs = select_one_scraped(page_url)\n",
    "        if jobs == []: #if all jobs have been scraped, break the loop\n",
    "            break\n",
    "        all_jobs.extend(jobs)\n",
    "        if len(all_jobs) > 100: #only scrape 100 jobs from each website\n",
    "            break\n",
    "    return all_jobs\n",
    "\n",
    "def output_new_jobs(website):\n",
    "    with open('existedjoblist-{}.csv'.format(website),'r') as f:\n",
    "        myreader = csv.reader(f)\n",
    "        url_existed = [row[4] for row in myreader] #read a row\n",
    "\n",
    "    with open('newjoblist.csv','a') as g:\n",
    "        mywriter = csv.writer(g)\n",
    "        for i in all_jobs:\n",
    "            if i[4] not in url_existed: #duplicate checking\n",
    "                mywriter.writerow(i)\n",
    "            \n",
    "    with open('existedjoblist-{}.csv'.format(website),'w') as h:\n",
    "        mywriter=csv.writer(h)\n",
    "        header=['Title','Company','Location','Date','URL']\n",
    "        mywriter.writerow(header) \n",
    "        mywriter.writerows(all_jobs)\n",
    "\n",
    "websites = [\n",
    "    {\n",
    "        \"website\": 'indeed',\n",
    "        \"base_url\": 'https://www.indeed.com/jobs?q=Data+Journalist+Internship&start=',\n",
    "        \"step\": 10,\n",
    "    },\n",
    "    {\n",
    "        \"website\": 'careers',\n",
    "        \"base_url\": 'https://careers.journalists.org/jobs/?keywords=data+OR+journalist+OR+internship&page=',\n",
    "        \"step\": 1,\n",
    "    }, \n",
    "    {\n",
    "        \"website\": 'jobsdb',\n",
    "        \"base_url\": 'https://hk.jobsdb.com/hk/search-jobs/data-journalist/',\n",
    "        \"step\": 1,\n",
    "    },\n",
    "]  \n",
    "\n",
    "for i in websites:\n",
    "    all_jobs = scrape_all_pages(i[\"base_url\"],i[\"step\"])\n",
    "    output_new_jobs(i[\"website\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digital Producer Internship - Summer 2019</td>\n",
       "      <td>Star Tribune Media Company, LLC.</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>30+ days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Professor in Computer and Informatio...</td>\n",
       "      <td>University of Michigan - Dearborn</td>\n",
       "      <td>Dearborn, Michigan</td>\n",
       "      <td>Today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assistant Professor in Computer and Informatio...</td>\n",
       "      <td>University of Michigan - Dearborn</td>\n",
       "      <td>Dearborn, Michigan</td>\n",
       "      <td>Today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Content &amp; News Writer - Asset Management</td>\n",
       "      <td>Morgan McKinley</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>Today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Digital Content Creator</td>\n",
       "      <td>Harvard University Graduate School of Education</td>\n",
       "      <td>USA - MA - Cambridge</td>\n",
       "      <td>Today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Assistant Professor in Computer and Informatio...</td>\n",
       "      <td>University of Michigan - Dearborn</td>\n",
       "      <td>Dearborn, Michigan</td>\n",
       "      <td>Today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Assistant Professor in Computer and Informatio...</td>\n",
       "      <td>University of Michigan - Dearborn</td>\n",
       "      <td>Dearborn, Michigan</td>\n",
       "      <td>Today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Site Reliability Engineer - DevOps</td>\n",
       "      <td>CBRE</td>\n",
       "      <td>Memphis,</td>\n",
       "      <td>Today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Principal Software Engineer (Backend)</td>\n",
       "      <td>CBRE</td>\n",
       "      <td>Memphis,</td>\n",
       "      <td>Today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SPEC-DIGITAL MARKETING FULL TIME SCOTTSDALE</td>\n",
       "      <td>HonorHealth</td>\n",
       "      <td>Scottsdale, Arizona</td>\n",
       "      <td>Today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Director, Marketing &amp; Communications</td>\n",
       "      <td>Association of Chamber of Commerce Executives</td>\n",
       "      <td>Alexandria, Virginia</td>\n",
       "      <td>Today</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0           Digital Producer Internship - Summer 2019   \n",
       "1   Assistant Professor in Computer and Informatio...   \n",
       "2   Assistant Professor in Computer and Informatio...   \n",
       "3            Content & News Writer - Asset Management   \n",
       "4                             Digital Content Creator   \n",
       "5   Assistant Professor in Computer and Informatio...   \n",
       "6   Assistant Professor in Computer and Informatio...   \n",
       "7           Senior Site Reliability Engineer - DevOps   \n",
       "8               Principal Software Engineer (Backend)   \n",
       "9         SPEC-DIGITAL MARKETING FULL TIME SCOTTSDALE   \n",
       "10               Director, Marketing & Communications   \n",
       "\n",
       "                                            Company                Location  \\\n",
       "0                  Star Tribune Media Company, LLC.         Minneapolis, MN   \n",
       "1                 University of Michigan - Dearborn      Dearborn, Michigan   \n",
       "2                 University of Michigan - Dearborn      Dearborn, Michigan   \n",
       "3                                   Morgan McKinley  London, United Kingdom   \n",
       "4   Harvard University Graduate School of Education    USA - MA - Cambridge   \n",
       "5                 University of Michigan - Dearborn      Dearborn, Michigan   \n",
       "6                 University of Michigan - Dearborn      Dearborn, Michigan   \n",
       "7                                              CBRE                Memphis,   \n",
       "8                                              CBRE                Memphis,   \n",
       "9                                       HonorHealth     Scottsdale, Arizona   \n",
       "10    Association of Chamber of Commerce Executives    Alexandria, Virginia   \n",
       "\n",
       "            Date  \n",
       "0   30+ days ago  \n",
       "1          Today  \n",
       "2          Today  \n",
       "3          Today  \n",
       "4          Today  \n",
       "5          Today  \n",
       "6          Today  \n",
       "7          Today  \n",
       "8          Today  \n",
       "9          Today  \n",
       "10         Today  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just a example, it's not real-time data\n",
    "import pandas\n",
    "df=pandas.read_csv('newjoblist.csv')\n",
    "df[['Title','Company','Location','Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
