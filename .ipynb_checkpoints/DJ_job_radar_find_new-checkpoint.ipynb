{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jl_dd0b79100dd35040\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_one_job(page_url):\n",
    "    job = {}\n",
    "    r = requests.get(page_url).text\n",
    "    data = BeautifulSoup(r,\"html.parser\")\n",
    "    job['title'] = data.find('h3', attrs={'class':\"icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title\"}).text\n",
    "    job['company'] = data.find('h4', attrs={'class':\"jobsearch-CompanyReview--heading\"}).text\n",
    "    job['location'] = data.find('div', attrs={'class':\"icl-u-lg-mr--sm icl-u-xs-mr--xs\"}).next_sibling.next_sibling.next_sibling.text\n",
    "    job['reviews'] = data.find('div', attrs={'class':\"icl-Ratings-count\"}).text\n",
    "    job['date'] = data.find('span', attrs={'class':\"icl-u-textColor--success\"}).next_sibling.replace('-','').strip()\n",
    "    return job\n",
    "\n",
    "def scrape_jobs_list_one_page(page_url): \n",
    "    r = requests.get(page_url).text\n",
    "    data = BeautifulSoup(r,\"html.parser\")\n",
    "    jobs_list = data.find_all('h2', attrs={'class':\"jobtitle\"})[0]['id']\n",
    "#     for my_url in my_urls:\n",
    "#         url ='{0}blog{1}'.format('http://initiumlab.com/',my_url['href'].split('/blog')[-1]) #format urls.\n",
    "#         # Fail try 1 : use slice to cut off ../../..\n",
    "#         # Fail try 2 : use blog instead of /blog to split. There are blog in the headline\n",
    "#         #print(url)\n",
    "#         article_urls.append(url)\n",
    "#     return article_urls\n",
    "    return jobs_list\n",
    "# jobs = []\n",
    "\n",
    "page_url = 'https://www.indeed.com/jobs?q=Data+Journalism+Internship&start=00'\n",
    "b = scrape_jobs_list_one_page(page_url)\n",
    "# a = scrape_one_job(page_url)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "def search_new_jobs(page_url)\n",
    "    with open('existedjoblist.csv','r') as f\n",
    "        myreader = csv.reader(f)\n",
    "        list_jobs_existed = [row[0] for row in myreader]\n",
    "    jobs_title = []\n",
    "    r = requests.get(page_url).text\n",
    "    data = BeautifulSoup(r,\"html.parser\")\n",
    "    n=len(data.find_all('h2'))\n",
    "    for i in range(0,n):\n",
    "        job = []    \n",
    "def scrape_one_job(page_url):\n",
    "    jobs= []\n",
    "    r = requests.get(page_url).text\n",
    "    data = BeautifulSoup(r,\"html.parser\")\n",
    "    n=len(data.find_all('h2'))\n",
    "    for i in range(0,n):\n",
    "        job = []\n",
    "        job.append(data.find_all('h2', attrs={'class':\"jobtitle\"})[i].a['title'])\n",
    "        job.append(data.find_all('span', attrs={'class':\"company\"})[i].text.strip())\n",
    "        job.append(data.find_all('span', attrs={'class':\"date\"})[i].text.strip())\n",
    "        job.append(data.find_all('span', attrs={'class':\"location\"})[i].text.strip())\n",
    "        jobs.append(job)\n",
    "    return jobs\n",
    "\n",
    "all_jobs=[]\n",
    "for i in range(0,200,10):\n",
    "    page_url = 'https://www.indeed.com/jobs?q=Data+Journalism+Internship&start={}'.format(i)\n",
    "    jobs = scrape_one_page(page_url)\n",
    "    all_jobs.extend(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
